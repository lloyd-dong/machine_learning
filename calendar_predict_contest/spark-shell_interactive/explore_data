//----------
5/12/29 02:09:26 INFO RandomForest:   init: 76.004552693
  total: 975.00306994
  findSplitsBins: 36.486319005
  findBestSplits: 898.443289388
  chooseSplits: 898.325215239
model: org.apache.spark.mllib.tree.model.RandomForestModel = 
TreeEnsembleModel classifier with 100 trees


    val labelAndPreds = trainingData.map { point =>
     val prediction = model.predict(point.features)
     (point.label, prediction)
    }
   val testErr = labelAndPreds.filter(r => r._1 != r._2).count.toDouble / trainingData.count()
   //Double = 0.005955632964474791

/------------------------
val pt_25_27 = sqlContext.jsonFile("s3n://lloyd-hadoop/contest_out/pt_25_27/")
pt_25_27.groupBy("praise").count.show
//null: nnn
//1: nn
//2:nn


log = pvf.filter(x =>x(5).toInt==0 && x(6).toInt==0).count().toString + ": 0 click and view records in PV" ::log
0, no such data

val onlyTrain = cleanT.map(t => (t(0),t(1),t(2))).subtract(cleanPV.map(p=>(p.dev_id,p.post_id,p.stat_date)))
log = onlyTrain.count() +": dev,post,date only in train data" ::log
count 189,661 //maybe view/click and praise are not on the same date, check the time, should be very near mid night, 00
todo: verify if time is near 00 for such data

//---train ---
//????!!!!假设 keyTrain.count = cleanT.count.也就是 dev,post,date 在train 中唯一，既 同一个人在同一天对同一个Post只做过一次操作 
//假设不成立!!!!!!!

val clearnT=trainRDD(- time 字段).distinct()
clearnT.count() 同人同一天对同一Post做了多次同样地操作) 
//474305 <-474564 = 259 

val keyTrain = clearnT.map(x => (x._1,x._2,x._3)).distinct().count
474292 <- 474305 = 17
//同人同一天对同一Post操作多次，操作不同 praise vs step" ::log


//----explore data----
//train count 474564
RDD[Array[Any]] count distinct because the key of Array
t:touple (a,b,c), t._1, t._2

val ptype = pvf.map(x=>(x(3),x(4).toInt)).distinct() //44553 <-2750063
val ptype = ptype.reduceByKey(_+_).filter(_._2>2) //count 1267,key(p_id) v(sum(type)) 有些post_id相同，但是type 不同

val s1=sqlContext.sql("select max(stat_date), min(stat_date) from pv").collect
s1.foreach(println) 
//[20151129,20151101] in 007_0

case class Post(p_id:String,title:String,content:String) 
val pF =sc.textFile("s3n://lloyd-hadoop/contest/post_data.txt")
//count 83837 = .distinct(), no duplicate
val pf1=pF.map(_.split("\t")).map(x=>x(0)).distinct()
//still 83837, no post_id is duplicated
//so, the type could be ignored, cause it shows one post could apear at card and lizhi forum
